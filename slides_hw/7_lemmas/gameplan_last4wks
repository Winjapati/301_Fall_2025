Day 1 : review, nesting

Day 2 : nested dicts

Day 3 : tokenization, nltk, wordnet

Day 4 : spacy

Day 5: spacy in other languages









Day 6 : filtering & comparison

- stopword filtering, topn analysis, comparison of two corpora
- Zipf's law, frequency patterns

Day 7 : writing simple functions

- overview of functions
- write small utilities for counting, cleaning, filtering

Day 8 : functions for analysis

- write functions that take a text and return:
  - number of words
  - top 10 lemmas
  - unique word ratio
- emphasize reuse and modular design

Day 9 : integrated analyzer

- full function pipeline:
  - input: txt file
  - process: clean --> tokenize --> lemmatize --> count
  - output: frequency df
- students prepare functions for visualization

Day 10 : visualization

- review bar charts
- use pd/matplotlib to visualize lemma frequencies
- histogram, pie, line examples
- labeling, titles, sorting aesthetics

Day 11 : in-class activity

- "text analyzer for linguists"
- students:
  - load a text
  - lemmatize and count
  - visualize top 10 lemmas
  - identify patterns
  - export results as graphic and csv



