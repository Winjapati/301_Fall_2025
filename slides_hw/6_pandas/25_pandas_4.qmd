---
title: "Computation for Linguists"
subtitle: "Pandasmonium: Day 4"
date: "October 22, 2025"
author: "Dr. Andrew M. Byrd"
format:
  revealjs:
    css: header_shrink.css
    theme: beige
    slide-number: true
    center: true
    toc: true
    toc-title: "Plan for the Day"
    toc-depth: 1
jupyter: python3
editor: source
---

# Review

-   What did you learn last time?

## Recap from Last Time

-   ddddddddd

## Review Activity

-   

# Loading up `csv` and `xls` files

## Reading / Writing Files

```python
# CSV
ref_df.to_csv("reflexes_summary.csv", index=False)
loaded = pd.read_csv("reflexes_summary.csv")
loaded.head()

# Excel (if needed)
# ref_df.to_excel("reflexes_summary.xlsx", index=False)
# pd.read_excel("reflexes_summary.xlsx")
```


## Quick Summaries

```python
df.describe(include="all")
df["family"].value_counts()
df["family"].unique()
```

## Grouping & Aggregation

```python
# Example small reflex table for demo
ref_df = pd.DataFrame({
    "Language": ["Latin","Greek","Sanskrit","Gothic","OCS","Latin"],
    "Family":   ["IE","IE","IE","Germanic","Slavic","IE"],
    "Reflexes": [8,10,12,4,3,5]
})

ref_df.groupby("Family")["Reflexes"].sum()
ref_df.groupby("Family").agg(
    total=("Reflexes","sum"),
    mean=("Reflexes","mean"),
    n=("Reflexes","count")
)
```


## Quick Visualization (optional)

```python
# Simple bar plot (requires matplotlib to be present)
counts = ref_df.groupby("Family")["Reflexes"].sum()
ax = counts.plot(kind="bar", title="Reflex Counts by Family")
ax.set_xlabel("Family")
ax.set_ylabel("Total Reflexes")
```

> Note: In some environments you may need:
> ```python
> import matplotlib.pyplot as plt
> plt.show()
> ```

## **Day 3 Activity â€” From Rows to Insight**

Using `ref_df` (or your own small table):

1. Group by `Family` and compute: total reflexes, mean reflexes, and count.
2. Sort families by total reflexes (descending).
3. Save the grouped summary to `family_reflexes.csv`.
4. Make a bar plot of total reflexes by family.

```python
summary = (ref_df
    .groupby("Family")["Reflexes"]
    .agg(total="sum", mean="mean", n="count")
    .sort_values(by="total", ascending=False)
)
summary
summary.to_csv("family_reflexes.csv")
```

---

# Appendix â€” Quick Reference

## Selection Cheatsheet

- **Columns:** `df["col"]`, `df[["col1","col2"]]`
- **Rows (position):** `df.iloc[0]`, `df.iloc[1:3]`
- **Rows (label):** `df.loc["a"]`, `df.loc["a":"c"]`
- **Cell:** `df.loc["a","col"]` or `df.iloc[0, 1]`
- **Filter:** `df[df["col"] == value]`, `df[(cond1) & (cond2)]`

## Common Ops

```python
df.rename(columns={"old":"new"})
df.drop(columns=["col"])
df.set_index("col")
df.reset_index(drop=True)
df.sort_values(by="col", ascending=False)
df.isna().sum()
df.fillna(0)
```

## Alignment & Combining

```python
s1.add(s2, fill_value=0)
pd.concat([df1, df2], axis=0, ignore_index=True)  # vertical
pd.concat([s1, s2], axis=1)                       # side-by-side
```

---

## Final Tips

- Keep indices simple early on; reset with `reset_index(drop=True)` if confused.
- Prefer unique column names and (eventually) a unique index.
- Build intuition with *small*, *visible* examples before loading big CSVs.


## Cleaning Data in Pandas

### Why Clean?
- Real data is messy.  
- Clean data means:
  - Consistent structure  
  - Clear column names  
  - No missing, duplicated, or mis-typed values  

---

## Cleaning **Before** You Build a DataFrame

> â€œIf it looks messy in your list or dictionary, pandas will just mirror that mess.â€

## Common Pre-DF Fixes
| Goal | Example |
|------|----------|
| Remove whitespace / newlines | `" word\n".strip()` |
| Standardize capitalization | `"Word".lower()` |
| Remove punctuation | `re.sub(r"[^\w\s]", "", text)` |
| Split text into tokens | `text.split()` |
| Validate list/dict lengths | `len(list)`, `list(zip(...))` |
| Handle placeholders | Replace `"NA"`, `"None"` with `None` |

ğŸ§  *Use basic Python + regex for text cleaning.*

---

## Cleaning **Within** the DataFrame

> â€œOnce itâ€™s a table, use pandas tools to fix the structure.â€

## Useful Methods
| Task | Example |
|------|----------|
| Inspect structure | `df.info()`, `df.shape`, `df.columns` |
| Rename columns | `df.rename(columns={"old":"new"})` |
| Drop columns or rows | `df.drop(columns=["col"])`, `df.dropna()` |
| Fill / replace values | `df.fillna("Unknown")`, `df.replace("?", None)` |
| Remove duplicates | `df.drop_duplicates()` |
| Convert data types | `df["col"] = df["col"].astype(int)` |
| String cleanup | `df["col"] = df["col"].str.strip().str.lower()` |
| Compute new columns | `df["new"] = df["col1"] + df["col2"]` |
| Sort and reset | `df.sort_values(["col"])`, `df.reset_index(drop=True)` |

---

## ğŸ§© A Mental Model

| Phase | Mindset | Tools |
|-------|----------|-------|
| **Before** | Clean the input | String methods, lists, dicts, `re` |
| **Inside DF** | Clean the structure | `.rename()`, `.dropna()`, `.astype()` |
| **After** | Analyze and summarize | `.loc`, `.sum()`, `.mean()`, `.groupby()` |



---

## ğŸ§­ Ten Core Methods to Remember

1. `df.info()` â€“ check structure  
2. `df.columns` â€“ list columns  
3. `df.rename()` â€“ fix column names  
4. `df.dropna()` / `df.fillna()` â€“ handle missing data  
5. `df.drop_duplicates()` â€“ remove repeats  
6. `df.astype()` â€“ convert data type  
7. `df["col"].str.lower()` â€“ text cleanup  
8. `df.replace()` â€“ fix placeholders  
9. `df.sort_values()` â€“ organize  
10. `df.reset_index()` â€“ tidy indices after filtering  

---

## Key Takeaway

> Python cleans **strings** and **lists**.  
> Pandas cleans **tables**.



# What You Can Do Now ğŸ§ 

## Linguistic Tasks Now Possible with Pandas

- âœ… **Build structured lexica**
  - Create and modify DataFrames of words, glosses, and languages
  - Filter or sort them instantly (no more manual loops)

- âœ… **Compare data across sources**
  - Merge two datasets (e.g., LIV + IEW)
  - Identify missing reflexes or mismatched glosses automatically

## Linguistic Tasks Now Possible with Pandas

- âœ… **Quantify linguistic patterns**
  - Count how many reflexes each family has per root
  - Measure which morphological types are most frequent

- âœ… **Clean and normalize datasets**
  - Capitalize, strip, or standardize glosses and forms
  - Fill in missing data (`NaN â†’ 0`) and rename columns in bulk

## Linguistic Tasks Now Possible with Pandas

- âœ… **Group and summarize**
  - Group by family, POS, or semantic field
  - Compute totals, averages, or frequencies per category

- âœ… **Visualize and export**
  - Create quick bar charts of linguistic statistics
  - Save clean CSVs for use in R, Excel, or later analysis

---

## The Big Shift

| Old Approach | New Approach with Pandas |
|---------------|---------------------------|
| Lists of strings | Structured tables |
| Loops over words | Operations over columns |
| Manual counting | Built-in aggregation |
| Hard-coded comparisons | Automatic alignment by label |
| Descriptive patterns | Quantitative insights |

> âš¡ You now think like a *linguistic data scientist*:  
> â€œEach row is a word; each column is a property; the DataFrame is my corpus.â€

---

